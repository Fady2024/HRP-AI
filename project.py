# -*- coding: utf-8 -*-
"""project (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-BLXr1B4F8ZjS8rLlmNJPWH8wPwtjvkC
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
import warnings
warnings.filterwarnings("ignore")

# Load diabetes dataset
data = pd.read_csv("dataset_diabetes/diabetic_data.csv")

data.info()

# Decode admission_type_id
admission_type_dict = {
    1: 'Emergency',
    2: 'Urgent',
    3: 'Elective',
    4: 'Newborn',
    5: 'Not Available',
    6: np.nan,
    7: 'Trauma Center',
    8: 'Not Mapped'
}
data['admission_type_id'] = data['admission_type_id'].map(admission_type_dict)

discharge_disposition_dict={
    1:'Discharged to home',
    2:'Discharged/transferred to another short term hospital',
    3:'Discharged/transferred to SNF',
    4:'Discharged/transferred to ICF',
    5:'Discharged/transferred to another type of inpatient care institution',
    6:'Discharged/transferred to home with home health service',
    7:'Left AMA',
    8:'Discharged/transferred to home under care of Home IV provider',
    9:'Admitted as an inpatient to this hospital',
    10:'Neonate discharged to another hospital for neonatal aftercare',
    11:'Expired',
    12:'Still patient or expected to return for outpatient services',
    13:'Hospice / home',
    14:'Hospice / medical facility',
    15:'Discharged/transferred within this institution to Medicare approved swing bed',
    16:'Discharged/transferred/referred another institution for outpatient services',
    17:'Discharged/transferred/referred to this institution for outpatient services',
    18:np.nan,
    19:'Expired at home. Medicaid only, hospice.',
    20:'Expired in a medical facility. Medicaid only, hospice.',
    21:'Expired, place unknown. Medicaid only, hospice.',
    22:'Discharged/transferred to another rehab fac including rehab units of a hospital .',
    23:'Discharged/transferred to a long term care hospital.',
    24:'Discharged/transferred to a nursing facility certified under Medicaid but not certified under Medicare.',
    25:'Not Mapped',
    26:'Unknown/Invalid',
    30:'Discharged/transferred to another Type of Health Care Institution not Defined Elsewhere',
    27:'Discharged/transferred to a federal health care facility.',
    28:'Discharged/transferred/referred to a psychiatric hospital of psychiatric distinct part unit of a hospital',
    29:'Discharged/transferred to a Critical Access Hospital (CAH).',
}
data['discharge_disposition_id']  = data['discharge_disposition_id'].map(discharge_disposition_dict)

# Decode admission_source_id
admission_source_dict={
    1:'Physician Referral',
    2:'Clinic Referral',
    3:'HMO Referral',
    4:'Transfer from a hospital',
    5:'Transfer from a Skilled Nursing Facility (SNF)',
    6:'Transfer from another health care facility',
    7:'Emergency Room',
    8:'Court/Law Enforcement',
    9:'Not Available',
    10:'Transfer from critial access hospital',
    11:'Normal Delivery',
    12:'Premature Delivery',
    13:'Sick Baby',
    14:'Extramural Birth',
    15:'Not Available',
    17:np.nan,
    18:'Transfer From Another Home Health Agency',
    19:'Readmission to Same Home Health Agency',
    20:'Not Mapped',
    21:'Unknown/Invalid',
    22:'Transfer from hospital inpt/same fac reslt in a sep claim',
    23:'Born inside this hospital',
    24:'Born outside this hospital',
    25:'Transfer from Ambulatory Surgery Center',
    26:'Transfer from Hospice',
}
data['admission_source_id'] = data['admission_source_id'].map(admission_source_dict)

# Display decoded categorical fields
data[['admission_type_id','discharge_disposition_id','admission_source_id']]

# Replace '?' with NaN values
data.replace('?',np.nan,inplace=True)

# Drop columns with excessive missing values or irrelevant for modeling
data.drop(columns=['weight', 'encounter_id', 'patient_nbr'], inplace=True)

# Remove rows with missing primary diagnosis (critical field)
data.dropna(subset=['diag_1'], inplace=True)

# Display count of null values in each column
print(data.isnull().sum())

# Handle missing values for each column
data['race'] = data['race'].fillna(data['race'].mode()[0])  # Fill with mode
data['A1Cresult'] = data['A1Cresult'].fillna('not measured')  # Medical test results
data['max_glu_serum'] = data['max_glu_serum'].fillna('not measured')
data['payer_code'] = data['payer_code'].fillna('unknown')
data['medical_specialty'] = data['medical_specialty'].fillna('unknown')
data['diag_2'] = data['diag_2'].fillna("NO_SECONDARY_DX")  # Secondary diagnosis
data['diag_3'] = data['diag_3'].fillna("NO_TERTIARY_DX")  # Tertiary diagnosis
data['admission_type_id'] = data['admission_type_id'].fillna('Not Available')
data['discharge_disposition_id'] = data['discharge_disposition_id'].fillna('Not Available')
data['admission_source_id'] = data['admission_source_id'].fillna('Not Available')
payer_data = data[['payer_code', 'readmitted']].copy()

# Verify all nulls are handle
data.isnull().sum()

data.head()

"""# Key Findings from Exploratory Data Analysis

### Readmission percentage
"""

data['readmitted_binary'] = (data['readmitted'] == '<30').astype(int)

# Analyzing the target variable 'readmitted'
readmitted_counts = data['readmitted'].value_counts()
readmitted_percent = (data['readmitted'].value_counts(normalize=True) * 100).round(2)

# Summary dataframe
readmission_summary = pd.DataFrame({
    'Count': readmitted_counts,
    'Percentage (%)': readmitted_percent
})


# visual representation
plt.figure(figsize=(10, 6))
ax = sns.countplot(x='readmitted', data=data, hue='readmitted', palette='viridis', legend=False)
# Adding count and percentage labels to the bars
for i, p in enumerate(ax.patches):
    height = p.get_height()
    percentage = readmitted_percent.iloc[i] if i < len(readmitted_percent) else 0
    ax.annotate(f"{height:,}\n({percentage}%)",
                (p.get_x() + p.get_width() / 2., height * 1.02),
                ha='center', va='baseline', fontsize=11)

plt.title('Distribution of Hospital Readmission', fontsize=16)
plt.xlabel('Readmission Status', fontsize=14)
plt.ylabel('Count of Patients', fontsize=14)
plt.tight_layout()
plt.show()

"""### Age ranges of patients"""

plt.figure(figsize=(12, 6))
age_counts = data['age'].value_counts().sort_index()
sns.barplot(x=age_counts.index, y=age_counts.values, hue=age_counts.index, palette='viridis',legend=False )
plt.title('Age Distribution of Patients', fontsize=16)
plt.xlabel('Age Group', fontsize=14)
plt.ylabel('Count', fontsize=14)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""### Gender of patients"""

# Analyzing gender distribution
data = data[data['gender'].isin(['Male', 'Female'])]
plt.figure(figsize=(10, 6))
gender_counts = data['gender'].value_counts()
# the different numbers of gender categories handling
#explode = [0.2] + [0] * (len(gender_counts) - 1)  # Explode the first piece (largest)

plt.pie(gender_counts, labels=gender_counts.index, autopct='%1.1f%%',
        startangle=90, colors=['pink', 'skyblue', 'lightgreen'][:len(gender_counts)])
plt.title('Gender Distribution', fontsize=16)
plt.tight_layout()
plt.show()

"""### Race of patients"""

# Analyzing race distribution
plt.figure(figsize=(10, 6))
race_counts = data['race'].value_counts()
explode = [0.1] + [0] * (len(race_counts) - 1)  # Explode the largest piece

plt.pie(race_counts, labels=race_counts.index, autopct='%1.1f%%',
        startangle=90, explode=explode, colors=sns.color_palette('Set3', len(race_counts)))
plt.title('Race Distribution', fontsize=16)
plt.tight_layout()
plt.show()

"""### Admission types in the hospital

### Admission types distribution that get readmitted in less than 30 days
"""

# function to calculate readmission rates by category
def calculate_readmission_rate(df, feature):
    """Calculate readmission rates for each category of a feature"""
    # Counting occurrences for each combination of feature and readmission status
    grouped = df.groupby([feature, 'readmitted']).size().unstack(fill_value=0)

    # Calculating total count for each category
    grouped['total'] = grouped.sum(axis=1)

    # Calculating readmission rates
    grouped['<30_days_rate'] = (grouped['<30'] / grouped['total'] * 100).round(2)
    grouped['>30_days_rate'] = (grouped['>30'] / grouped['total'] * 100).round(2)
    grouped['total_readmission_rate'] = ((grouped['<30'] + grouped['>30']) / grouped['total'] * 100).round(2)

    # rates and counts
    return grouped[['<30_days_rate', '>30_days_rate', 'total_readmission_rate', 'total']]

valid_admission = data.dropna(subset=['admission_type_id'])
admission_readmission = calculate_readmission_rate(valid_admission, 'admission_type_id')
admission_readmission = admission_readmission.sort_values('<30_days_rate', ascending=False)

plt.figure(figsize=(12, 6))
sns.barplot(x=admission_readmission.index, y=admission_readmission['<30_days_rate'],hue=admission_readmission.index, palette='viridis', legend=False)
plt.title('30-Day Readmission Rate by Admission Type', fontsize=16)
plt.xlabel('Admission Type', fontsize=14)
plt.ylabel('30-Day Readmission Rate (%)', fontsize=14)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""### Readmission rates by admission source

"""

top_sources = data['admission_source_id'].value_counts().nlargest(10).index
source_data = data[data['admission_source_id'].isin(top_sources)]
source_readmission = calculate_readmission_rate(source_data, 'admission_source_id')
source_readmission = source_readmission.sort_values('<30_days_rate', ascending=False)

plt.figure(figsize=(14, 7))
sns.barplot(x=source_readmission.index, y=source_readmission['<30_days_rate'], hue=source_readmission.index,palette='viridis', legend=False)
plt.title('30-Day Readmission Rate by Top 10 Admission Sources', fontsize=16)
plt.xlabel('Admission Source', fontsize=14)
plt.ylabel('30-Day Readmission Rate (%)', fontsize=14)
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

"""### Seeing the relation between the diagnosis 1 with the readmission before 30 days"""

def categorize_diagnosis(code):
    if pd.isna(code):  # Handle missing values
        return "Unknown"

    code = str(code).strip()  # Ensure it's a string and remove spaces

    # Check if it's a numeric ICD code
    if code.replace(".", "").isdigit():
        code = float(code)  # Convert to float
        if 1 <= code <= 139:
            return "Infectious Diseases"
        elif 140 <= code <= 239:
            return "Cancer & Neoplasms"
        elif 240 <= code <= 279:
            return "Endocrine Disorders"
        elif 280 <= code <= 289:
            return "Blood Disorders"
        elif 290 <= code <= 319:
            return "Mental Health Disorders"
        elif 320 <= code <= 389:
            return "Nervous System Diseases"
        elif 390 <= code <= 459:
            return "Heart & Circulatory Conditions"
        elif 460 <= code <= 519:
            return "Respiratory Diseases"
        elif 520 <= code <= 579:
            return "Digestive System Diseases"
        elif 580 <= code <= 629:
            return "Kidney & Urinary Disorders"
        elif 630 <= code <= 679:
            return "Pregnancy-Related Conditions"
        elif 680 <= code <= 709:
            return "Skin Disorders"
        elif 710 <= code <= 739:
            return "Muscle & Bone Conditions"
        elif 740 <= code <= 759:
            return "Congenital Disorders"
        elif 760 <= code <= 779:
            return "Perinatal Conditions"
        elif 780 <= code <= 799:
            return "Symptoms & Non-Specific Conditions"
        elif 800 <= code <= 999:
            return "Injuries & Poisoning"
        else:
            return "Unknown ICD Code"

    # If it's an alphanumeric V, W, X, or Y code
    elif code.startswith("V"):
        return "External Injury (Vehicle-related)"
    elif code.startswith("W"):
        return "External Injury (Falls, Accidents)"
    elif code.startswith("X"):
        return "External Injury (Poisoning, Assault)"
    elif code.startswith("Y"):
        return "External Injury (Other Causes)"
    else:
        return "Unknown"

# Apply function to the dataset
data["diag_category"] = data["diag_1"].apply(categorize_diagnosis)

# Calculating readmission rates by primary diagnosis category
diag_readmission = calculate_readmission_rate(data, 'diag_category')
diag_readmission = diag_readmission.sort_values('<30_days_rate', ascending=False)

plt.figure(figsize=(12, 6))
sns.barplot(x=diag_readmission.index, y=diag_readmission['<30_days_rate'], palette='viridis', legend=False)
plt.title('30-Day Readmission Rate by Primary Diagnosis Category', fontsize=16)
plt.xlabel('Diagnosis Category', fontsize=14)
plt.ylabel('30-Day Readmission Rate (%)', fontsize=14)
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

"""### Seeing the relation between A1C and readmission"""

filtered_df = data[data["A1Cresult"] != "not measured"]
a1c_readmission = calculate_readmission_rate(filtered_df, 'A1Cresult')
a1c_readmission = a1c_readmission.sort_values('<30_days_rate', ascending=False)


# Create bar plot
sns.countplot(x="A1Cresult", data=filtered_df, palette="viridis")
plt.xticks(rotation=0)
plt.title("Filtered Bar Plot")
plt.show()

"""### Seeing the relation between the glucose serum results and readmission"""

filtered_df = data[data["max_glu_serum"] != "not measured"]
glu_readmission = calculate_readmission_rate(filtered_df, 'max_glu_serum')
glu_readmission = glu_readmission.sort_values('<30_days_rate', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x=glu_readmission.index, y=glu_readmission['<30_days_rate'],hue=glu_readmission.index, palette='viridis', legend=False)
plt.title('30-Day Readmission Rate by Glucose Serum Test Result', fontsize=16)
plt.xlabel('Glucose Serum Test Result', fontsize=14)
plt.ylabel('30-Day Readmission Rate (%)', fontsize=14)
plt.tight_layout()
plt.show()

"""### Seeing the effect of using a diabetes medication on readmission"""

diabetes_med_readmission = calculate_readmission_rate(data, 'diabetesMed')

plt.figure(figsize=(10, 6))
sns.barplot(x=diabetes_med_readmission.index, y=diabetes_med_readmission['<30_days_rate'],hue= diabetes_med_readmission.index, palette='viridis', legend=False)
plt.title('30-Day Readmission Rate by Diabetes Medication Usage', fontsize=16)
plt.xlabel('Diabetes Medication', fontsize=14)
plt.ylabel('30-Day Readmission Rate (%)', fontsize=14)
plt.tight_layout()

plt.show()

"""### Seeing the effect of changing the medication on readmission"""

# Calculating readmission rates by medication change
change_readmission = calculate_readmission_rate(data, 'change')

plt.figure(figsize=(10, 6))
sns.barplot(x=change_readmission.index, y=change_readmission['<30_days_rate'], palette='viridis')
plt.title('30-Day Readmission Rate by Medication Change', fontsize=16)
plt.xlabel('Medication Change', fontsize=14)
plt.ylabel('30-Day Readmission Rate (%)', fontsize=14)
plt.tight_layout()
plt.show()

"""### Seeing the effect of insulin on readmission"""

insulin_readmission = calculate_readmission_rate(data, 'insulin')
insulin_readmission = insulin_readmission.sort_values('<30_days_rate', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x=insulin_readmission.index, y=insulin_readmission['<30_days_rate'],hue=insulin_readmission.index, palette='viridis', legend=False)
plt.title('30-Day Readmission Rate by Insulin Treatment', fontsize=16)
plt.xlabel('Insulin Treatment', fontsize=14)
plt.ylabel('30-Day Readmission Rate (%)', fontsize=14)
plt.tight_layout()
plt.show()

"""### Seeing the effect of specific medication on readmission"""

med_columns = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',
               'glimepiride', 'acetohexamide', 'glipizide', 'glyburide',
               'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'readmitted_binary']

med_readmission_rates = {}
for med in med_columns:
    # Filtering data for patients with increased dosage
    med_up_data = data[data[med] == 'Up']
    if len(med_up_data) > 0:
        # Calculating 30-day readmission rate
        med_readmission_rates[med] = (med_up_data['readmitted_binary'].mean() * 100).round(2)

# Creating a DataFrame for easier plotting
if med_readmission_rates:
    med_rates_df = pd.DataFrame(list(med_readmission_rates.items()), columns=['Medication', 'Readmission_Rate'])
    med_rates_df = med_rates_df.sort_values('Readmission_Rate', ascending=False)

    plt.figure(figsize=(14, 7))
    sns.barplot(x='Medication', y='Readmission_Rate', data=med_rates_df, palette='viridis')
    plt.title('30-Day Readmission Rate for Patients with Increased Medication Dosage', fontsize=16)
    plt.xlabel('Medication', fontsize=14)
    plt.ylabel('30-Day Readmission Rate (%)', fontsize=14)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

data.info()

"""### Previous visists to readmitted column"""

plt.figure(figsize=(12, 6))

# Scatter plot with readmitted status as color/hue
plt.subplot(1, 3, 1)
plt.title('Distribution of Previous Outpatient Visits', fontsize=14)
sns.scatterplot(x=data["number_outpatient"],
                y=data["readmitted"],
                hue=data["readmitted"],
                alpha=0.6)

# Scatter plot with readmitted status as color/hue
plt.subplot(1, 3, 2)
plt.title('Distribution of Previous Emergency Visits', fontsize=14)
sns.scatterplot(x=data["number_emergency"],
                y=data["readmitted"],
                hue=data["readmitted"],
                alpha=0.6)

plt.subplot(1, 3, 3)
plt.title('Distribution of Previous Inpatient Visits', fontsize=14)
sns.scatterplot(x=data["number_inpatient"],
                y=data["readmitted"],
                hue=data["readmitted"],
                alpha=0.6)


plt.tight_layout()
plt.show()

"""### Seeing the relation between the payer code and readmission

### Correlation matrix
"""

'''ArithmeticError
# Selecting numerical features
numerical_features = [
    'time_in_hospital', 'num_lab_procedures', 'num_procedures',
    'num_medications', 'number_outpatient', 'number_emergency',
    'number_inpatient', 'number_diagnoses', "readmitted_mapped"
]

# Creating correlation matrix
correlation_matrix = data[numerical_features].corr()

# Plot heatmap of correlations
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Matrix of Numerical Features', fontsize=16)
plt.tight_layout()
plt.show()
'''

data = data[data['gender'].isin(['Male', 'Female'])]
medication_cols = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',
                  'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone',
                  'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide',
                  'examide', 'citoglipton', 'glyburide-metformin', 'glipizide-metformin',
                  'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone']

# Calculate number of medications taken
data['num_medications_taken'] = data[medication_cols].apply(lambda x: (x != 'No').sum(), axis=1)

data.info()

# Data Preprocessing: Encode features and standardize
categorical_cols = data.select_dtypes(include=['object']).columns.tolist()
categorical_cols.remove("age")

le = LabelEncoder()

for col in categorical_cols:
    data[col] = le.fit_transform(data[col])

data.head()

data["age"].unique()

map_age = {
    '[0-10)': 0,
    '[10-20)': 1,
    '[20-30)': 2,
    '[30-40)': 3,
    '[40-50)': 4,
    '[50-60)': 5,
    '[60-70)': 6,
    '[70-80)': 7,
    '[80-90)': 8,
    '[90-100)': 9
}
data['age'] = data['age'].map(map_age)

# Standardize only the numeric columns, excluding one-hot encoded columns
scaler = StandardScaler()
# Define numeric columns that are not one-hot encoded
numeric_cols = ['time_in_hospital', 'num_lab_procedures', 'num_procedures',
                'num_medications', 'number_outpatient', 'number_emergency',
                'number_inpatient', 'number_diagnoses', 'num_medications_taken']
data[numeric_cols] = scaler.fit_transform(data[numeric_cols])

data.head()

data.info()

data.drop(columns=['readmitted_binary'], inplace=True)

data['readmitted']

data.info()

numeric_cols = ['time_in_hospital', 'num_lab_procedures', 'num_procedures',
                'num_medications', 'number_outpatient', 'number_emergency',
                'number_inpatient', 'number_diagnoses', 'num_medications_taken']
mask = (data[numeric_cols] > -3) & (data[numeric_cols] < 3)
data = data[mask.all(axis=1)]

data.info()

# Map readmitted for binary classification
map_readmitted = {
    0: 0,
    1: 1,
    2: 1
}
data['readmitted'] = data['readmitted'].map(map_readmitted)

"""### Importing Libraries"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import  confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score

"""###  Train-Test Split"""

X = data.drop(columns=['readmitted'])
y = data['readmitted']

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) #Stratified sampling to maintain the proportion of classes in the target variable

"""###  Logistic Regression"""

LogisticRegressionModel = LogisticRegression(max_iter=1000)
LogisticRegressionModel.fit(x_train, y_train)
#predicting on the training set
y_pred_train = LogisticRegressionModel.predict(x_train)
# Predicting on the test set
y_pred_logistic = LogisticRegressionModel.predict(x_test)

print ("Accuracy on training set:", accuracy_score(y_train, y_pred_train))
print("Accuracy on test set:", accuracy_score(y_test, y_pred_logistic))


print("F1 Score:", f1_score(y_test, y_pred_logistic))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_logistic))
print("Precision Score:", precision_score(y_test, y_pred_logistic))
print("Recall Score:", recall_score(y_test, y_pred_logistic))
print("ROC AUC Score:", roc_auc_score(y_test, y_pred_logistic))

"""###  SVM"""

svm = SVC()
svm.fit(x_train, y_train)
# Predicting on the training set
y_pred_train = svm.predict(x_train)
# Predicting on the test set
y_pred_svm = svm.predict(x_test)
print ("Accuracy on training set:", accuracy_score(y_train, y_pred_train))
print("Accuracy on test set:", accuracy_score(y_test, y_pred_svm))
print("F1 Score:", f1_score(y_test, y_pred_svm))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_svm))
print("Precision Score:", precision_score(y_test, y_pred_svm))
print("Recall Score:", recall_score(y_test, y_pred_svm))
print("ROC AUC Score:", roc_auc_score(y_test, y_pred_svm))

"""###  Decision Tree"""

decision_tree = DecisionTreeClassifier()
decision_tree.fit(x_train, y_train)
# Predicting on the training set
y_pred_train = decision_tree.predict(x_train)
# Predicting on the test set
y_pred_decision_tree = decision_tree.predict(x_test)
print ("Accuracy on training set:", accuracy_score(y_train, y_pred_train))
print("Accuracy on test set:", accuracy_score(y_test, y_pred_decision_tree))
print("F1 Score:", f1_score(y_test, y_pred_decision_tree))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_decision_tree))
print("Precision Score:", precision_score(y_test, y_pred_decision_tree))
print("Recall Score:", recall_score(y_test, y_pred_decision_tree))
print("ROC AUC Score:", roc_auc_score(y_test, y_pred_decision_tree))

"""### Random Forest"""

random_forest = RandomForestClassifier()
random_forest.fit(x_train, y_train)
# Predicting on the training set
y_pred_train = random_forest.predict(x_train)
# Predicting on the test set
y_pred_random_forest = random_forest.predict(x_test)
print ("Accuracy on training set:", accuracy_score(y_train, y_pred_train))
print("Accuracy on test set:", accuracy_score(y_test, y_pred_random_forest))
print("F1 Score:", f1_score(y_test, y_pred_random_forest))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_random_forest))
print("Precision Score:", precision_score(y_test, y_pred_random_forest))
print("Recall Score:", recall_score(y_test, y_pred_random_forest))
print("ROC AUC Score:", roc_auc_score(y_test, y_pred_random_forest))

"""### KNN"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(x_train, y_train)
# Predicting on the training set
y_pred_train = knn.predict(x_train)
# Predicting on the test set
y_pred_knn = knn.predict(x_test)
print ("Accuracy on training set:", accuracy_score(y_train, y_pred_train))
print("Accuracy on test set:", accuracy_score(y_test, y_pred_knn))
print("F1 Score:", f1_score(y_test, y_pred_knn))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_knn))
print("Precision Score:", precision_score(y_test, y_pred_knn))
print("Recall Score:", recall_score(y_test, y_pred_knn))
print("ROC AUC Score:", roc_auc_score(y_test, y_pred_knn))